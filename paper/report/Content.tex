
%mainfile: Networks.tex

\pagestyle{fancy} 
\lhead{Atelier Nueromod√©lisation, 2017}
\rhead{}
\rfoot{\thepage}
\cfoot{}
\lfoot{~\theauthor}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}


\title{Paper Implementation: Reproduce some basic results
of the article ``Generating Coherent Patterns of Activity from
Chaotic Neural Networks''\vspace{-0.5em}}
%\preauthor{} \postauthor{} 
\author{Hsieh Yu-Guan}
\date{\today}
\maketitle

\thispagestyle{fancy}

\setcounter{secnumdepth}{0}

\section{Summary}

In this report we'll be working on the article ``Generating Coherent
Patterns of Activity from Chaotic Neural Networks'' published by 
David Sussillo and L.F. Abbott in 2009. In the work of D. Sussillo and L.F.
Abbott, they were interested in neural networks that are capable of
generating complex activity patterns either spontaneously or in response to
different stimuli.

The network is meant to be chaotic before training, i.e.
its activity should be highly sensitive to initial conditions. This is
acheieved by the usage of strong recurrent synaptic connections inside it. 
The so-called FORCE learning algorithm is then employed to modify
synaptic weights either external to or within the network. 
After the training phase, the network will be able to produce a wide 
variety of complex output patterns and we can switch between different
outputs by controlling the input signal.

Now let's come back to this report itself. I only worked on a relatively 
small part of the article: the generation of periodic patterns in the 
absence inputs by using FORCE learning. Moreover, three distinct network
structures are considered in the article (this will be detailed later on), 
but only the first one, which is probably also the simpest, is implemented 
here.

\section{Introduction}

When we're performing some motor action, what is the source of the nerual
activity that initiates and carries out this behavior? In the paper of
D. Sussillo and L.F. Abbott, they examined the hypothesis that such actions 
may come from the reorgnaization of spontaneous neural activity, which then
leads us to another question: how can a such reorgnaization happen?

The objective is thus to find a possible synaptic weight modification rule
that allows the network activity to be reorgnaized into coherent patterns 
required to produce complex motor actions after training. However, comparing
with feedfoward architectures, the training of a recurrent network is
shown to be much more difficult due to several reasons.
First, feeding erroneous output back into a network during training may
prevent its activity from converging. Secondly, in a recurrent network
the credit assignement for output errors becomes quite a hard problem because
of the presence of recurrent weights. Finally, while using a network that
display chaotic activity prior to training can be beneficial, chaos
must be avoided during the learning phase.

FORCE learning solved these problems by keeping the errors always small
and forcing the synaptic modifications to be strong and rapid during traing.
This is quite different from classic learning algorithms which usually
reduce the errors little by little. Therefore, the goal of FORCE learning
is not significant error reduction, but rather reducing the amount of
modification needed to keep the errors small.

According to the article, the contribution of FORCE learning can be
viewed from two different angles. From a biological point of view, it can
be regarded as a model for learning-induced moficifation of biological
models. Or more simply, it can just be seen as a powerful algorithm that
is able to construct recurrent networks being able to generate complex
and controlable output patterns.

\section{Network Structures}

The network that was studied in the paper and will be study here is composed
of individual neurons characterized by their firing rates and
sparsely interconnected through excitatory and inhibiroty synapses of 
various strengths (when it comes to the biological reality, we may need to
seperate group of excitatory and inhibitory neurons, but when we're modeling
neural circuits, such details become less important). Initially, the
connectivity and synaptic strengths of the network are chosen randomly.

The next problem is the definition of the output of the networks. The
technical choice is to define it as a linear combination of neuronal
activities. Formally, if at time $t$, we assemble the firing rates of all
the neurons into a column vector $\mathbf{r}(t)$, and the weights 
connecting these neurons to the output is described by the column vector
$\mathbf{w}(t)$, then the network output is

\[z(t) = \mathbf{w}^{\top}\mathbf{r}(t).\]

Schematically, this output will be stored in a readout unit and its
value may be fed back into the network (it depends on the concrete
structure). Though thus far the network output is only a scalar, by using
several differents decoding vectors $\mathbf{w}$ we can easily define
a multidimensional readout. This is exactly what D. Sussillo and L.F.
Abbott did in their paper when they later asked the network to generate
multiple outputs; however this point will not covered by the report.

Now that we have defined $z$ as the output of the network, the goal
of the algorithm is to set $z = f$ for somme target function 
$f: t \mapsto f(t)$. Either $z$ is generated in the abscence of any input
or it may depend on inputs of the network in a specific way. In the scope
of this report, only the first case will be discussed.

Finally, as shown in \autoref{fig: network_structures}, three different 
network structures are proposed in the article. In the first structure
the feedback to the generator network is provided directly from the readout
unit. During training, we modify only the decoding vector $\mathbf{w}$
and the internal recurrent synaptic strengths are left intact.
Such a network is simple but far from realistic: every neuron receives the
same feedback (though it may be weighted differently) and this feedback
itself originates from an abstract output that doesn't exist in real circuit.
To address this problem, two other structures more biologically plausible
are given. In the second structure we use a separated feedback network to 
supply feedback and in the third one modifications on internal synaptic
strengths are allowed. Without giving more details here, I just mention 
that after proper adaptions, FORCE learning can be carried out on the
three structures and yield promising results indifferent to the
underlying network structure.


\begin{figure}[H]
  \centering
  \includegraphics[width=0.32\textwidth, valign=t]{network_structure1}
  \hfill
  \includegraphics[width=0.32\textwidth, valign=t]{network_structure2}
  \hfill
  \includegraphics[width=0.32\textwidth, valign=t]{network_structure3}
  \vspace{0.8em}
  \caption{
    \textbf{Network Architectures (picture from the paper).}\\[0.1em]
    In all three cases, a linear readout unit derives an output $z$
    from the firing rates $\mathbf{r}$ of the recurrent generator network.
    Only connections shown in red are subject to modification.\\[0.1em]
    (A) The output of the readout unit is directly fed back to the
    generator network.\\[0.1em]
    (B) Feedback to the generator network is provided by a separated
    feedback network recurrently connected and whose inputs come from
    the generator network through synapses of strength $\mathbf{J}^{FG}$
    (red) that are also modified during training.\\[0.1em]
    (C) A simple recurrent network with no external feedback, but all
    synaptic strengths $\mathbf{J}^{GG}$ are subject to be modified by 
    the learning algorithm.
  }
  \label{fig: network_structures}
\end{figure}

Now let's put all the elements together and give a formal description of
the network that will be used in the framework of this report. First
we have a column vector $\mathbf{x}$ containing some abstract values of
each neuron (just for modeling convenience, or one may be able to find
some biological meaning for this vector that I ignore here). The firing
rates are computed by $\mathbf{r} = \tanh(\mathbf{x})$ (application of
the function term by term). The dynamic of the network is governed by
the equation

\[
  \tau \frac{d\mathbf{x}}{dt} = 
  -\mathbf{x} + g_{GG}\mathbf{J}^{GG}\mathbf{r}
  + g_{Gz} \mathbf{J}^{Gz} z,
\]

where $\tau$ is the caracteristic time, $\mathbf{J}^{GG}$ and 
$\mathbf{J}^{Gz}$ are respectively the matrix of internal synaptic 
weights and the vector of connection weights from the readout unit 
to the generator network (the feadback loop), and $z$ is the output
defined earlier. $g_{GG}$ is introduced to scale the strengths of 
the recurrent connections. When $g<1$ the network is inactive prior to
training; on the contrary if $g>1$ the network exhibits chaotic spontaneous
activity. $g_{Gz}$ plays a similar role with regard to the connections
from the readout unit to the main network.

We use moreover a sparseness parameter $\rho$ to impose sparsity on the 
network: each pairwise connection is set and held to 0 with probability 
$1 - \rho$. In the whole report, we'll choose $\tau=10$ ms, $g_{GG} = 1.5$,
$g_{Gz} = 1$, and the network contains $N=1000$ neurons unless otherwise 
stated. For initialization, nonzero elements of $\mathbf{J}^{GG}$ are drawn
independently from a Gaussian distribution with zero mean and variances
$1/(\rho N)$ while elements of $\mathbf{J}^{Gz}$ are drawn from a uniform
distribution between -1 and 1. We notice that feedback synapses are stronger
than internal ones in order to have an appreciable effect on the
network activity and this is necessary for suppressing the inherent
chaos of the network. Similarly, elements of $\mathbf{w}$ and 
$\mathbf{x}$ are respectively generated by Gaussian distributions with zero 
means and standard deviations $\sqrt{1/(\rho N)}$ or $\sigma_x = 0.5$.

\section{FORCE learning}

The term FORCE learning stands for first-order reduced and controlled error
learning. Training of recurrent networks is in general a hard problem as 
already mentioned in the introduction (even though here we modify only
the readout vector $\mathbf{w}$, the presence of the feedback loop makes
any effect of the modification difficult to predict). Since erroneous output
shouldn't be fed back to the network, the proposed algorithm must rapidly 
reduce the magnitude of the difference between the actual and desired output
to a small value, and then keep it small while searching for the proper
fixed readout vector that can generate the target function without further
modification of this vector.

The general schema of such an algorithm consists of updating $\mathbf{w}$
at times separated by an interval $\Delta t$ based on the readout error
at this moment which is defined by:

\[e_-(t) = \mathbf{w}^{\top}(t-\Delta t)\mathbf{r}(t) - f(t).\]

\noindent
The minus subscript that this is the error prior to weight update at time
$t$. The update of $\mathbf{w}(t-\Delta t)$ to $\mathbf{w}(t)$ should
allow us decrease the error so that

\[e_+(t) = \mathbf{w}^{\top}(t)\mathbf{r}(t) - f(t)\]

\noindent
satisfies $|e_+(t)| < |e_-(t)|$. Since the end of the training takes place
only when the decoding vector $\mathbf{w}$ stabilizes and no longer changes,
this also requires $e_+(t)/e_-(t) \rightarrow 1$. 
Note that $\Delta t$ is the interval of time
between modifications of readout weights and doesn't necessarily equal to
the basic integration time step for the network simulation. In fact,
for the simulations carried out throughout this report, I take 
$\Delta t = 1$ ms whereas the basic integration time step is 0.1 ms.

Knowing all of this, it's still far from obvious to deduce the appropriate
modification rules that will work. In the paper, D. Sussillo and L.F. Abbott
express their favor to use the recursive least-squares (RLS) algorithm here.
I'll not dig into the mathematical details of this algorithm, but briefly
in our case it gives

\[\mathbf{w}(t) = \mathbf{w}(t-\Delta t)\mathbf{P}(t)\mathbf{r}(t),\]

\noindent
where $\mathbf{P}(t)$ is an $N \times N$ matrix that is updated at the same
time as the weights according to the rule

\[\mathbf{P}(t) = \mathbf{P}(t-\Delta t) 
  - \frac{\mathbf{P}(t-\Delta t)\mathbf{r}(t)\mathbf{r}^{\top}(t)
    \mathbf{P}(t-\Delta t)}
    {1 + \mathbf{r}^{\top}\mathbf{P}(t-\Delta t)\mathbf{r}(t)}.\]




\iffalse

Besides studying the structure and function of a single neuron, it's also
important to understand what may happen when neurons communicate between them.
In this report we'll thus look at some simple models of neural networks.
What will be their dynamics and expressive power? 
(P.S. we'll ignore all physical units for the whole report.)

\section{Some simple networks}

\subsection{Neuron with autapse}

Let's start by working on the simplest model that one can ever imagine:
there's only one neuron in the network, and its output feeds back onto 
itself via a synapse (such a synapse is called an ``autapse''). 
We note $x$ the neuron's firing rate, and it obeys the equation

\[\dot{x}(t) = -x(t) + f(wx(t)+I)\]

\noindent
where $w = 0.04$ is the strength of the synaptic connection and $I = -2$ 
is the external (and inhibitory) background input which is constant.
Finally, $f$ is the input-output (or activation) function of the neuron having
a sigmoidal form and is given by

\[f(s) = 50(1 + \tanh(s))\]

\noindent
where $s$ is the total input of the neuron.

To see that $f$ is indeed a sigmoidal function, we plot it for the range 
$s \in [-10, 10]$ as shown in \autoref{fig: activate}. Next, we plot the
derivative of the firing rate $\dot{x}$ as a function of $x$ 
(\autoref{fig: x_derivative}). The form should be easily predictable.
The function $f$ is first stretched out and then shifted to the right,
before we finally add the linear function $x \mapsto -x$ to it.

We observe three zero-crossings in this graph. Let's call them respectively
$x_1$, $x_2$ and $x_3$ with $x_1 < x_2 < x_3$. In fact we get $x_1 \sim 2$,
$x_2 = 50$ and $x_3 \sim 98$. They are the fixed points of the dynamics.
However, $x_1$ and $x_3$ are stable while $x_2$ is unstable.
We can see that if $x$ lies between $x_1$ and $x_2$, $\dot{x}$ is negative
so $x$ will be ``attracted'' to $x_1$, and if $x$ is smaller than $x_1$,
$\dot{x}$ is positive and $x$ will converge to $x_1$. The same analysis
works for $x_3$.

\newpage

\vspace{-1em}
\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\linewidth]{autapse1}
  \caption{The activtion function $f$ of the neuron}
  \label{fig: activate}
\end{figure}

\vspace{-1em}
\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\linewidth]{autapse2}
  \caption{$\dot(x)$ as a function of $x$}
  \label{fig: x_derivative}
\end{figure}

Now we'll simulate the dynamics of the system by taking a time step 
$\Delta t = 0.1$ and a total time period $T = 100$. First consider
$x(0) = 49$.

\vspace{-1em}
\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\linewidth]{autapse3}
  \caption{The evolution of $x$ for $x(0) = 49$}
\end{figure}

\noindent
As predicted before $x$ is attracted to the dynamics attractor $x_1$.
We redo the simulation for $x(0) = 50$.

\vspace{-1em}
\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\linewidth]{autapse4}
  \caption{The evolution of $x$ for $x(0) = 50$}
\end{figure}

\noindent
This time since 50 is itself a fixed point of the dynamics, the system 
is at equilibrium and the solution doesn't change with time (though 50
is a repeller). Finally let $x(0) = 51$.

\vspace{-1em}
\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\linewidth]{autapse5}
  \caption{The evolution of $x$ for $x(0) = 51$}
\end{figure}

\noindent
It's the symmetry of the case $x(0) = 49$. Between the repeller $x_2$ and
the attractor $x_3$, $x$ evolves towards $x_3$.

We then add noise to the system, so the differential equation becomes

\[\dot{x}(t) = -x(t) + f(wx(t)+I) + \sigma\eta(t)\]

\noindent
where $\eta(t)$ is Gaussian white noise with varaiance 1. First we suppose 
$\sigma = 5$ and we simulate for $x(0) = 49$.

\vspace{-1em}
\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\linewidth]{autapse6}
  \caption{The evolution of $x$ with noise $\sigma = 5$ for $x(0) = 49$}
\end{figure}

We see that there are two different scenarios. With noise we can no longer
ensure that the system will converge towards $x_1$. Since the evolutions of
the system are very different for $x < 50$ and $x > 50$, and 49 is close
to 50, slight noise in the model may lead to totaly distinct results. This can
be again shown for $x(0) = 50$ and $x(0) = 51$.

\vspace{-1em}
\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\linewidth]{autapse7}
  \caption{The evolution of $x$ with noise $\sigma = 5$ for $x(0) = 50$}
\end{figure}

\vspace{-1em}
\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\linewidth]{autapse8}
  \caption{The evolution of $x$ with noise $\sigma = 5$ for $x(0) = 51$}
\end{figure}

Also notice that for $x(0) = 50$, $x$ will not stay anymore at the value 50 
because as mentioned before, $x_2 = 50$ is a repeller. In a model with noise,
the probability that $x$ is always 50 becomes null. 

In all the above examples, though noise can have great influence on the 
evolution of the system, once $x$ gets far enough from $x_2$, the evolution
is still mainly dominated by the drift term $-x(t) + f(wx(t)+I)$.
Nonetheless, this is not the case for a greater noise level, for example,
when $\sigma = 80$, as shown in the figure at the top of the next page.

\vspace{-1em}
\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\linewidth]{autapse9}
  \caption
    {The evolution of $x$ with noise $\sigma = 80$ for $x(0) = 49, 50, 51$}
\end{figure}

As the resulting curves follow almost the same pattern for different 
initial values of $x$, I plot all of them on the same graph. It's not worth
it to plot several simulations for a same $x(0)$ because we would not be able
to see great differences. In short, the evolution of $x$ is donimated by
the noise term and becomes just noisy.

\subsection{Circuit with mutual inhibition}

The second model we'll discuss here is made up of two neurons that are coupled
by mutual inhibition. We note the firing rate of the two neurons respectively
$x_1$ and $x_2$, then the whole system is governed by the differential
equations

\begin{gather*}
  \dot{x}_1 = -x_1(t) + f(wx_2(t) + I)\\
  \dot{x}_2 = -x_2(t) + f(wx_1(t) + I)
\end{gather*}

\noindent
where $f$ is defined as before and the inhibitory synaptic weights are given
by $w = 0.1$. The external inputs are now excitatory, $I = 5$.

We may also want to use the vector notation that would turn out to be quite
useful when the population of neurons gets larger, then the system of
differential equations can be put in the form:

\[\dot{\mathbf{x}} = -\mathbf{x}(t) + f(\mathbf{Wx}(t) + \mathbf{I})\]

\noindent
where $\mathbf{x}$ is the vector of firing rates, $\mathbf{W}$ is the synaptic 
weight matrix and $\mathbf{I}$ is the vector of input currents. In this
particular case, we have

\[
  \mathbf{x}(t) = \left(
    \begin{array}{c}
      x_1(t)\\
      x_2(t)
    \end{array}\right) \qquad
  %
  \mathbf{W} = \left(
    \begin{array}{cc}
      0 & w\\
      w & 0
    \end{array}\right) \qquad
  %
  \mathbf{I} = \left(
    \begin{array}{c}
      I\\
      I
    \end{array}\right).
\]

To study the dynamics of this system, we first plot its nullclines, that is,
the line for which $\dot{x}_1(t)=0$ and the line for which $\dot{x}_2(t)=0$.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\linewidth]{mutual1}
  \caption
    {The nullclines of the system of two mutual inhibitory neurons}
\end{figure}

We observe three crossing points of the the two lines. From left to right,
we name them respectively $z_1$, $z_2$ and $z_3$ (so $z_2 = (50,50)$).
These are the points such that $\dot{x}_1 = \dot{x}_2 = 0$. In other words,
they're the fixed points of the dynamics. The plane is then divided into six
zones and in each zone the system evolves in a specific direction. To put it
simply, on the left of the blue line we have $\dot{x}_1 > 0$ while on the
right $\dot{x}_1 < 0$. Similarly, below the orange line we get
$\dot{x}_2 > 0$ whereas above it $\dot{x}_2 < 0$.

To better undestand what this implies, we simulate the system and plot the 
evolution of the firing rates for different initial conditions in the figure 
below.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\linewidth]{mutual2}
  \caption
    {The evolution of the firing rates for different initial conditions}
\end{figure}

The initial conditions that are considered here are $(-50, -50)$, $(-40, 150)$,
$(-25, 50)$, $(3, 50)$, $(75, -50)$, $(100, 130)$, $(140, 141)$ and 
$(150, 90)$. First we notice that all of the simulations end up in some fixed
point and the directions of the evolutions follow roughly what is described
above. Further, it seems that (but without rigorous mathematical proof here)
given the initial condition $(x(0),y(0))$, if $x(0) < y(0)$ the system evolves
to $z_1$; if $x(0) = y(0)$ the system converges to $z_2$; finally if 
$x(0) > y(0)$ the system moves to $z_3$.

The yellow arrow serves as quite a good example: the initial condition is 
$(150, 151)$, and the system gets once very clear to $z_2$ but then it again
leaves away from this point and converges to $z_1$ at the end. As a result,
being fixed point, $z_1$ and $z_3$ are stable while $z_2$ is unstable. 
Finally, a plot of the vector field of derivatives can better 
explain all of this.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\linewidth]{mutual3}
  \caption{Derivatives at different points of the system}
\end{figure}

\subsection{Conclusion}

In this section, we have investigated two relatively simple networks and spent
time studying their dynamics. Several simulations have also been carried out.
We saw that there were diffrent kinds of fixed points of dynamics and if the
external currents were constant, the system would evolve towards some final 
state (which was often an attractor). Finally, the presence of noise may more
or less affect the evolution of the system.


\section{Hopfield Network}

\subsection{Description}

In the rest of the report we'll be interested in the continuous Hopfield 
model. The dynamics of the network is given the differential equation

\[\dot{\mathbf{x}} = -\mathbf{x}(t) + f(\mathbf{Wx}(t)) + 
  \sigma\mathbf{\eta}(t).\]

\noindent
The vector notation is adopted and a noise is also introduced.
Throughout the whole section, we set the dimension of $\mathbf{x}$ to be 
$N=64$ and thus $\mathbf{W}$ is a $64\times64$ matrix. For the sake of 
simplicity, we will take $f(x) = \mathrm{sgn}(x)$ for the moment being, and 
we use the convention that $\mathrm{sgn}(0) = 0$. As a result, $\mathbf{x}$
is typically a vector of reels between -1 and 1.

A such network can act as an associative memory system. For example, to store
one pattern $\mathbf{p}$ we set the weight matrix to 

\[\mathbf{W} = \frac{1}{N} \mathbf{p}\mathbf{p}^{\top}.\]

\noindent
Then it's quite easy to see that $\mathbf{p}$ is a fixed point of the
dynamics. For illustration purpose, we'll plot the activity of the neurons
as a figure containing $[8 \times 8]$ cases.

\subsection{Simulations}

To start we say that the network is meant to store just one pattern 
(\autoref{fig: Hopfield_one} - \textsf{A}) and the
noise level is $\sigma = 0.1$. As shown in \autoref{fig: Hopfield_one} -
\textsf{B}, the system may converge to $\mathbf{p}$. However, chances are 
that the it evolves towards $-\mathbf{p}$ 
(\autoref{fig: Hopfield_one} - \textsf{C}). We can easily show
that $-\mathbf{p}$ is indeed also a fixed point of the dynamics, but since
it's not a pattern that we aim to store, it's called a spurious state.
Looking at the differential equation, one may notice that there is still
another fixed point of the system: when $\mathbf{x} = \mathbf{0}$. 
Nonetheless, unlike the two previous fixed points, this one is not stable
and noise can bring the system away from it (\autoref{fig: Hopfield_one} -
\textsf{D}).

To store more patterns, say, $M$ patterns from $\mathbf{p}_1$ to 
$\mathbf{p}_M$, the general rule is to construct the weight matrix as

\[\mathbf{W} = \frac{1}{N} \sum_{i=1}^M \mathbf{p}_i\mathbf{p}_i^{\top}.\]

\noindent
For example in \autoref{fig: Hopfield_two} we store two patterns $\mathbf{p}$
and $\mathbf{q}$ in the network. We start from 
initial conditions that are respectively ``close'' to $\mathbf{p}$,
$-\mathbf{p}$, $\mathbf{q}$ and $-\mathbf{q}$. By close we mean that we change
the activity of a relative small number of neurons to its opposite value 
(from 1 to -1 and from -1 to 1). We see that the network is always able
to evolve to the right fixed point.

However, surely we cannot store an unlimited number of patterns in the 
network. The network capcity depends on the explicit patterns that we want
to store. In \autoref{fig: Hopfield_six} we try to store six different 
patterns in the Hopfield network, but it doen't work perfectly.
In \autoref{fig: Hopfield_six} - \textsf{B} we start from a state that is
close to the first pattern we'd like to store and we manage to retrieve it
at the end. On the contrary, sometimes even though the initial condition 
is very similar to one of the stored patterns, we may fail to converge to 
this pattern and ends up in a state that is neither stored nor opposite of 
one that is stored in our network (\autoref{fig: Hopfield_six} -
\textsf{C}, the initial condition is close to the fifth pattern we aim to
store).

If we start from a random initial state, the network may converge to
a stored pattern (\autoref{fig: Hopfield_six} - \textsf{D}), but as
described above, it can also evolve towards an arbitrary spurious state
that cannot be directly predicted from the stored patterns
(\autoref{fig: Hopfield_six} - \textsf{E, F}). Moreover, the convergence
might take a longer time and sometimes is not as direct as before 
(\autoref{fig: Hopfield_six} - \textsf{D}, the network finally converges
to the second stored pattern though by showing only 50 simulation steps it may 
not yet be totally clear).

\newpage
\null
\vfill
\begin{figure}[H]
  \centering
  %
  \begin{subfigure}{0.28\textwidth}
    \centering
    \includegraphics[width=\textwidth]{one_p0}
    \textsf{A}
  \end{subfigure}
  %
  \hspace{0.7em}
  %
  \begin{minipage}{0.62\textwidth}
    \begin{subfigure}{\textwidth}
      \textsf{B}
      \centering
      \includegraphics[width=0.18\textwidth]{one_4_0}
      \includegraphics[width=0.18\textwidth]{one_4_1}
      \includegraphics[width=0.18\textwidth]{one_4_2}
      \includegraphics[width=0.18\textwidth]{one_4_3}
      \includegraphics[width=0.18\textwidth]{one_4_4}
    \end{subfigure}\\[0.6em]
    %
    \begin{subfigure}{\textwidth}
      \textsf{C}
      \centering
      \includegraphics[width=0.18\textwidth]{one_3_0}
      \includegraphics[width=0.18\textwidth]{one_3_1}
      \includegraphics[width=0.18\textwidth]{one_3_2}
      \includegraphics[width=0.18\textwidth]{one_3_3}
      \includegraphics[width=0.18\textwidth]{one_3_4}
    \end{subfigure}\\[0.6em]
    %
    \begin{subfigure}{\textwidth}
      \textsf{D}
      \centering
      \includegraphics[width=0.18\textwidth]{one_0_0}
      \includegraphics[width=0.18\textwidth]{one_0_1}
      \includegraphics[width=0.18\textwidth]{one_0_2}
      \includegraphics[width=0.18\textwidth]{one_0_3}
      \includegraphics[width=0.18\textwidth]{one_0_4}
    \end{subfigure}
    %
  \end{minipage}
  \vspace{1.2em}
  \caption{Store one pattern in a Hopfield network.
           \textsf{A.} The stored pattern.
           \textsf{B.C.D.} Simulations with different initial conditions
           (between two successive picutres we carry out 10 steps of
           simulation).}
  \label{fig: Hopfield_one}
\end{figure}

\vfill

\begin{figure}[H]
  \centering
  %
  \begin{minipage}{0.275\textwidth}
    \begin{subfigure}{\textwidth}
      \centering
      \includegraphics[width=\textwidth]{two_p0}
      \textsf{A}
    \end{subfigure}\\[0.3em]
    %
    \begin{subfigure}{\textwidth}
      \centering
      \includegraphics[width=\textwidth]{two_p1}
      \textsf{B}
    \end{subfigure}
  \end{minipage}
  %
  \hspace{0.7em}
  %
  \begin{minipage}{0.62\textwidth}
    \begin{subfigure}{\textwidth}
      \textsf{C}
      \centering
      \includegraphics[width=0.22\textwidth]{two_1_0}
      \includegraphics[width=0.22\textwidth]{two_1_1}
      \includegraphics[width=0.22\textwidth]{two_1_2}
      \includegraphics[width=0.22\textwidth]{two_1_3}
    \end{subfigure}\\[0.8em]
    %
    \begin{subfigure}{\textwidth}
      \textsf{D}
      \centering
      \includegraphics[width=0.22\textwidth]{two_2_0}
      \includegraphics[width=0.22\textwidth]{two_2_1}
      \includegraphics[width=0.22\textwidth]{two_2_2}
      \includegraphics[width=0.22\textwidth]{two_2_3}
    \end{subfigure}\\[0.8em]
    %
    \begin{subfigure}{\textwidth}
      \textsf{E}
      \centering
      \includegraphics[width=0.22\textwidth]{two_3_0}
      \includegraphics[width=0.22\textwidth]{two_3_1}
      \includegraphics[width=0.22\textwidth]{two_3_2}
      \includegraphics[width=0.22\textwidth]{two_3_3}
    \end{subfigure}\\[0.8em]
    %
    \begin{subfigure}{\textwidth}
      \textsf{F}
      \centering
      \includegraphics[width=0.22\textwidth]{two_4_0}
      \includegraphics[width=0.22\textwidth]{two_4_1}
      \includegraphics[width=0.22\textwidth]{two_4_2}
      \includegraphics[width=0.22\textwidth]{two_4_3}
    \end{subfigure}
    %
  \end{minipage}
  \vspace{1.2em}
  \caption{Store two patterns in a Hopfield network.
           \textsf{A.B.} Stored patterns.
           \textsf{C.D.E.F.} Simulations with different initial conditions
           that are close to stored patterns or their opposites.}
  \label{fig: Hopfield_two}
\end{figure}
\vfill

\newpage

\null
\vfill

\begin{figure}[H]
  \centering
  \begin{subfigure}{\textwidth}
    \textsf{A}
    \centering
    \includegraphics[width=0.15\textwidth]{six_p0}
    \includegraphics[width=0.15\textwidth]{six_p1}
    \includegraphics[width=0.15\textwidth]{six_p2}
    \includegraphics[width=0.15\textwidth]{six_p3}
    \includegraphics[width=0.15\textwidth]{six_p4}
    \includegraphics[width=0.15\textwidth]{six_p5}
  \end{subfigure}\\[1em]
  %
  \hspace{1em}\rule{0.95\textwidth}{1.8pt}\\
  \vspace{1em}
  %
  \begin{subfigure}{\textwidth}
    \textsf{B}
    \centering
    \includegraphics[width=0.15\textwidth]{six_1_0}
    \includegraphics[width=0.15\textwidth]{six_1_1}
    \includegraphics[width=0.15\textwidth]{six_1_2}
    \includegraphics[width=0.15\textwidth]{six_1_3}
    \includegraphics[width=0.15\textwidth]{six_1_4}
    \includegraphics[width=0.15\textwidth]{six_1_5}
  \end{subfigure}\\[0.8em]
  %
  \begin{subfigure}{\textwidth}
    \textsf{C}
    \centering
    \includegraphics[width=0.15\textwidth]{six_9_0}
    \includegraphics[width=0.15\textwidth]{six_9_1}
    \includegraphics[width=0.15\textwidth]{six_9_2}
    \includegraphics[width=0.15\textwidth]{six_9_3}
    \includegraphics[width=0.15\textwidth]{six_9_4}
    \includegraphics[width=0.15\textwidth]{six_9_5}
  \end{subfigure}\\[0.8em]
  %
  \begin{subfigure}{\textwidth}
    \textsf{D}
    \centering
    \includegraphics[width=0.15\textwidth]{six_13_0}
    \includegraphics[width=0.15\textwidth]{six_13_1}
    \includegraphics[width=0.15\textwidth]{six_13_2}
    \includegraphics[width=0.15\textwidth]{six_13_3}
    \includegraphics[width=0.15\textwidth]{six_13_4}
    \includegraphics[width=0.15\textwidth]{six_13_5}
  \end{subfigure}\\[0.8em]
  %
  \begin{subfigure}{\textwidth}
    \textsf{E}
    \centering
    \includegraphics[width=0.15\textwidth]{six_8_0}
    \includegraphics[width=0.15\textwidth]{six_8_1}
    \includegraphics[width=0.15\textwidth]{six_8_2}
    \includegraphics[width=0.15\textwidth]{six_8_3}
    \includegraphics[width=0.15\textwidth]{six_8_4}
    \includegraphics[width=0.15\textwidth]{six_8_5}
  \end{subfigure}\\[0.8em]
  %
  \begin{subfigure}{\textwidth}
    \textsf{F}
    \centering
    \includegraphics[width=0.15\textwidth]{six_16_0}
    \includegraphics[width=0.15\textwidth]{six_16_1}
    \includegraphics[width=0.15\textwidth]{six_16_2}
    \includegraphics[width=0.15\textwidth]{six_16_3}
    \includegraphics[width=0.15\textwidth]{six_16_4}
    \includegraphics[width=0.15\textwidth]{six_16_5}
  \end{subfigure}
  \vspace{1.2em}
  \caption{Try to store six patterns in a Hopfield network.
           \textsf{A.} Stored patterns.
           \textsf{B.C.D.E.F.} Simulations with different initial conditions.}
  \label{fig: Hopfield_six}
\end{figure}

\vfill

\newpage

Now how about replacing sgn by tanh for the activation function? To simplify
the task, we'll first remove noise from the network and we attempt to
store only one pattern in the network. As shown in 
\autoref{fig: Hopfield_tanh},
the values of final states are proportional to those of $\mathbf{p}$,
but neuron activities are in general of much smaller magnitudes. The 
convergence is also much slower. 

It's easy to imagine that in this case, the presence of noise can degrade
severely the performance of the network. Indeed when we put again
$\sigma=0.1$, the result is shown in \autoref{fig: Hopfield_tanh_noise}. 
Neuron activities seem to be pure noise and we can hardly retrieve any
information from it (notice that until now for the same simulation in
one figure two successive images are separated by 10 simulation steps
while from now on they'll be separated by 50 simulation steps).

The problem becomes even more complex if we store several patterns in 
the network. Again we'll remove noise from the model and this time we want
to store two patterns in the network. Several scenarios can occur: the
network may just work as before except a final state with much lower 
activity level (\autoref{fig: Hopfield_tanh_two}); however, chances are
the two stored patterns are no longer fixed points of the dynamics and
even starting from the stored patterns we fall into another state that
doesnt't appear to be reltated to what we want to store 
(\autoref{fig: Hopfield_tanh_two2}). We notice also that the convergence
of the system takes much longer time.

\subsection{Conclusion}
With the differential equation that is given at the beginning of the
section and the general rule used to generate the weight matrix, 
we have simulated the dynamics of the network under various situations. 
We saw that when $f = \mathrm{sgn}$ and if we stored just a small number
of patterns the Hopfield network could act correctly as an associative 
memory system despite the presence of noise.
However the network capacity is without doubt limited and many spurious
states could appear if we tried to store too many patterns in a network.

When $f = \tanh$, the dynamics of the system seems to be more complicated.
The values of the final states are much closer to 0, noise can be fatal to
the system, the convergence is much slower and unexpected attractors
may appear when we want to store more than one patterns.

We didn't do any mathematical proofs in this section, but to study more
in details the Hopfield network, new notions must be introduced (e.g.
energy of the network) and this will be a topic much more complex and
beyond the scope of this report.

\begin{figure}[H]
  \centering
  %
  \begin{subfigure}{0.26\textwidth}
    \centering
    \includegraphics[width=\textwidth]{tanh_p0}
    \textsf{A}
  \end{subfigure}
  %
  \hspace{0.7em}
  %
  \begin{minipage}{0.64\textwidth}
    \begin{subfigure}{\textwidth}
      \textsf{B}
      \centering
      \includegraphics[width=0.15\textwidth]{tanh_1_0}
      \includegraphics[width=0.15\textwidth]{tanh_1_1}
      \includegraphics[width=0.15\textwidth]{tanh_1_2}
      \includegraphics[width=0.15\textwidth]{tanh_1_3}
      \includegraphics[width=0.15\textwidth]{tanh_1_4}
      \includegraphics[width=0.15\textwidth]{tanh_1_5}
    \end{subfigure}\\[0.6em]
    %
    \begin{subfigure}{\textwidth}
      \textsf{C}
      \centering
      \includegraphics[width=0.15\textwidth]{tanh_3_0}
      \includegraphics[width=0.15\textwidth]{tanh_3_1}
      \includegraphics[width=0.15\textwidth]{tanh_3_2}
      \includegraphics[width=0.15\textwidth]{tanh_3_3}
      \includegraphics[width=0.15\textwidth]{tanh_3_4}
      \includegraphics[width=0.15\textwidth]{tanh_3_5}
    \end{subfigure}\\[0.6em]
    %
    \begin{subfigure}{\textwidth}
      \textsf{D}
      \centering
      \includegraphics[width=0.15\textwidth]{tanh_5_0}
      \includegraphics[width=0.15\textwidth]{tanh_5_1}
      \includegraphics[width=0.15\textwidth]{tanh_5_2}
      \includegraphics[width=0.15\textwidth]{tanh_5_3}
      \includegraphics[width=0.15\textwidth]{tanh_5_4}
      \includegraphics[width=0.15\textwidth]{tanh_5_5}
    \end{subfigure}
    %
  \end{minipage}
  \vspace{1.2em}
  \caption{Store one pattern in a Hopfield network with $f = \tanh$ 
           without noise.
           \textsf{A.} The stored pattern.
           \textsf{B.C.D.} Simulations with random initial conditions.}
  \label{fig: Hopfield_tanh}

\end{figure}

\newpage
\null
\vfill

\begin{figure}[H]
  \centering
  %
  \begin{subfigure}{\textwidth}
    \hspace{0.6em}
    \textsf{A}
    \includegraphics[width=0.11\textwidth]{tanh_p0}
  \end{subfigure}\\[1em]
  %
  \hspace*{1.2em}\rule{0.95\textwidth}{1.8pt}\\[1em]
  %
  \begin{subfigure}{\textwidth}
    \hspace{0.6em}
    \textsf{B}
    \includegraphics[width=0.11\textwidth]{tanh_noise_1_0}
    \includegraphics[width=0.11\textwidth]{tanh_noise_1_1}
    \includegraphics[width=0.11\textwidth]{tanh_noise_1_2}
    \includegraphics[width=0.11\textwidth]{tanh_noise_1_3}
    \includegraphics[width=0.11\textwidth]{tanh_noise_1_4}
    \includegraphics[width=0.11\textwidth]{tanh_noise_1_5}
    \includegraphics[width=0.11\textwidth]{tanh_noise_1_6}
    \includegraphics[width=0.11\textwidth]{tanh_noise_1_7}
  \end{subfigure}\\[0.6em]
  %
  \begin{subfigure}{\textwidth}
    \hspace{0.6em}
    \textsf{C}
    \includegraphics[width=0.11\textwidth]{tanh_noise_2_0}
    \includegraphics[width=0.11\textwidth]{tanh_noise_2_1}
    \includegraphics[width=0.11\textwidth]{tanh_noise_2_2}
    \includegraphics[width=0.11\textwidth]{tanh_noise_2_3}
    \includegraphics[width=0.11\textwidth]{tanh_noise_2_4}
    \includegraphics[width=0.11\textwidth]{tanh_noise_2_5}
    \includegraphics[width=0.11\textwidth]{tanh_noise_2_6}
    \includegraphics[width=0.11\textwidth]{tanh_noise_2_7}
  \end{subfigure}
  %
  \vspace{1.2em}
  \caption{Store one pattern in a Hopfield network with $f = \tanh$ 
           with noise.
           \textsf{A.} The stored pattern.
           \textsf{B.C.} Simulations with random initial conditions
           (between two successive picutres we carry out 50 steps of
           simulation).}
  \label{fig: Hopfield_tanh_noise}

\end{figure}

\vfill

\begin{figure}[H]
  %
    \begin{subfigure}{\textwidth}
      \hspace{1em}
      \textsf{A}
      \includegraphics[width=0.15\textwidth]{tanh_two_p0}
      \includegraphics[width=0.15\textwidth]{tanh_two_p1}
    \end{subfigure}\\[1em]
  %
  \hspace*{2.2em}\rule{0.95\textwidth}{1.8pt}\\[1em]
  %
    \begin{subfigure}{\textwidth}
      \hspace{1em}
      \textsf{B}
      \includegraphics[width=0.15\textwidth]{tanh_two_6_0}
      \includegraphics[width=0.15\textwidth]{tanh_two_6_1}
      \includegraphics[width=0.15\textwidth]{tanh_two_6_2}
      \includegraphics[width=0.15\textwidth]{tanh_two_6_3}
      \includegraphics[width=0.15\textwidth]{tanh_two_6_4}
      \includegraphics[width=0.15\textwidth]{tanh_two_6_5}
    \end{subfigure}\\[0.6em]
    %
    \begin{subfigure}{\textwidth}
      \hspace{1em}
      \textsf{C}
      \includegraphics[width=0.15\textwidth]{tanh_two_7_0}
      \includegraphics[width=0.15\textwidth]{tanh_two_7_1}
      \includegraphics[width=0.15\textwidth]{tanh_two_7_2}
      \includegraphics[width=0.15\textwidth]{tanh_two_7_3}
      \includegraphics[width=0.15\textwidth]{tanh_two_7_4}
      \includegraphics[width=0.15\textwidth]{tanh_two_7_5}
    \end{subfigure}\\[0.6em]
    %
    \begin{subfigure}{\textwidth}
      \hspace{1em}
      \textsf{D}
      \includegraphics[width=0.15\textwidth]{tanh_two_9_0}
      \includegraphics[width=0.15\textwidth]{tanh_two_9_1}
      \includegraphics[width=0.15\textwidth]{tanh_two_9_2}
      \includegraphics[width=0.15\textwidth]{tanh_two_9_3}
      \includegraphics[width=0.15\textwidth]{tanh_two_9_4}
      \includegraphics[width=0.15\textwidth]{tanh_two_9_5}
    \end{subfigure}
    %
  \vspace{1.2em}
  \caption{Store two patterns in a Hopfield network with $f = \tanh$ 
           without noise, with success.
           \textsf{A.} Stored patterns.
           \textsf{B.C.D.} Simulations with random initial conditions.}
  \label{fig: Hopfield_tanh_two}

\end{figure}

\vfill

\newpage
\null
\vfill

\begin{figure}[H]
  %
    \begin{subfigure}{\textwidth}
      \hspace{1em}
      \textsf{A}
      \includegraphics[width=0.15\textwidth]{tanh_two2_p0}
      \includegraphics[width=0.15\textwidth]{tanh_two2_p1}
    \end{subfigure}\\[1em]
  %
  \hspace*{2.2em}\rule{0.95\textwidth}{1.8pt}\\[1em]
  %
    \begin{subfigure}{\textwidth}
      \hspace{2em}
      \includegraphics[width=0.15\textwidth]{tanh_two2_1_0}
      \includegraphics[width=0.15\textwidth]{tanh_two2_1_1}
      \includegraphics[width=0.15\textwidth]{tanh_two2_1_2}
      \includegraphics[width=0.15\textwidth]{tanh_two2_1_3}
      \includegraphics[width=0.15\textwidth]{tanh_two2_1_4}
      \includegraphics[width=0.15\textwidth]{tanh_two2_1_5}\\
      \hspace*{1em}
      \textsf{B}
      \includegraphics[width=0.15\textwidth]{tanh_two2_1_6}
      \includegraphics[width=0.15\textwidth]{tanh_two2_1_7}
      \includegraphics[width=0.15\textwidth]{tanh_two2_1_8}
      \includegraphics[width=0.15\textwidth]{tanh_two2_1_9}
      \includegraphics[width=0.15\textwidth]{tanh_two2_1_10}
      \includegraphics[width=0.15\textwidth]{tanh_two2_1_11}
    \end{subfigure}\\[0.6em]
    %
    \begin{subfigure}{\textwidth}
      \hspace{2em}
      \includegraphics[width=0.15\textwidth]{tanh_two2_3_0}
      \includegraphics[width=0.15\textwidth]{tanh_two2_3_1}
      \includegraphics[width=0.15\textwidth]{tanh_two2_3_2}
      \includegraphics[width=0.15\textwidth]{tanh_two2_3_3}
      \includegraphics[width=0.15\textwidth]{tanh_two2_3_4}
      \includegraphics[width=0.15\textwidth]{tanh_two2_3_5}\\
      \hspace*{1em}
      \textsf{C}
      \includegraphics[width=0.15\textwidth]{tanh_two2_3_6}
      \includegraphics[width=0.15\textwidth]{tanh_two2_3_7}
      \includegraphics[width=0.15\textwidth]{tanh_two2_3_8}
      \includegraphics[width=0.15\textwidth]{tanh_two2_3_9}
      \includegraphics[width=0.15\textwidth]{tanh_two2_3_10}
      \includegraphics[width=0.15\textwidth]{tanh_two2_3_11}
    \end{subfigure}\\[0.6em]
    %
    \begin{subfigure}{\textwidth}
      \hspace{2em}
      \includegraphics[width=0.15\textwidth]{tanh_two2_8_0}
      \includegraphics[width=0.15\textwidth]{tanh_two2_8_1}
      \includegraphics[width=0.15\textwidth]{tanh_two2_8_2}
      \includegraphics[width=0.15\textwidth]{tanh_two2_8_3}
      \includegraphics[width=0.15\textwidth]{tanh_two2_8_4}
      \includegraphics[width=0.15\textwidth]{tanh_two2_8_5}\\
      \hspace*{1em}
      \textsf{D}
      \includegraphics[width=0.15\textwidth]{tanh_two2_8_6}
      \includegraphics[width=0.15\textwidth]{tanh_two2_8_7}
      \includegraphics[width=0.15\textwidth]{tanh_two2_8_8}
      \includegraphics[width=0.15\textwidth]{tanh_two2_8_9}
      \includegraphics[width=0.15\textwidth]{tanh_two2_8_10}
      \includegraphics[width=0.15\textwidth]{tanh_two2_8_11}
    \end{subfigure}\\[0.6em]
    %
  \vspace{1.2em}
  \caption{Store two patterns in a Hopfield network with $f = \tanh$ 
           without noise, new fixed points appear instead of the stored ones.
           \textsf{A.} Stored patterns.
           \textsf{B.C.} Simulations starting from stored patterns.
           \textsf{D.} Simulations with random initial condition.}
  \label{fig: Hopfield_tanh_two2}

\end{figure}

\vfill
\fi
